{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OSError while attempting to symlink the latest log directory\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pendulum\n",
    "import pytz\n",
    "import requests\n",
    "from datetime import datetime, timedelta, time\n",
    "from airflow import DAG\n",
    "from airflow.models import Variable\n",
    "from airflow.operators.python import PythonOperator\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_google_key = \"../../Credenciales/servacc_bigquery.json\"\n",
    "bq_table = \"conexion-datos-rdf.audio_digital.acumulado_diario\"\n",
    "\n",
    "cl = pytz.timezone(\"America/Santiago\")\n",
    "local_tz = pendulum.timezone(\"America/Santiago\")\n",
    "utc = pytz.utc\n",
    "fmt= '%Y-%m-%d %H:%M:%S'\n",
    "fmt_d= '%Y-%m-%d'\n",
    "dias_reemplazo = 10\n",
    "now_dt = datetime.now(cl)\n",
    "#now_dt = datetime(2022,7,1)\n",
    "\n",
    "content_types = {\n",
    "    \"horizonte.cl\": [None],\n",
    "    \"oasisfm.cl\": [None],\n",
    "    \"playfm.cl\": [None],\n",
    "    \"sonarfm.cl\": [None],\n",
    "    \"tele13radio.cl\": [None]\n",
    "}\n",
    "\n",
    "grupo = {\n",
    "    \"horizonte.cl\": \"3570670d5064d58ee8ccdd3650506e3a\",\n",
    "    \"oasisfm.cl\": \"35bfeb595ed83ebec22c1e3b5ed28f7f\",\n",
    "    \"playfm.cl\": \"06c2d59cd238c5848572bc1874acb044\",\n",
    "    \"sonarfm.cl\": \"2757a2c258842237e149c98e55073b31\",\n",
    "    \"tele13radio.cl\": \"5ae0b4ae44d45dbbaef992ea99512079\"\n",
    "}\n",
    "\n",
    "content_live = {\n",
    "    \"horizonte.cl\": \"601415b58308405b0d11c82a\",\n",
    "    \"oasisfm.cl\": \"5c915497c6fd7c085b29169d\",\n",
    "    \"playfm.cl\": \"5c8d6406f98fbf269f57c82c\",\n",
    "    \"sonarfm.cl\": \"5c915724519bce27671c4d15\",\n",
    "    \"tele13radio.cl\": \"5c915613519bce27671c4caa\"\n",
    "}\n",
    "\n",
    "stream_vip = {\n",
    "     5: \"b3583f38d358a82ecb3b6783664f1305\"\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sesion_platform():\n",
    "\n",
    "    login_platform = {\"username\": \"jlizana@rdfmedia.cl\",\n",
    "                      \"password\": \"jlizana123\", \"withJWT\": \"true\", \"login\": \"Login\"}\n",
    "    session = requests.session()\n",
    "    r = session.post(\"https://platform.mediastre.am/login\",\n",
    "                     data=login_platform)\n",
    "    r = session.get('https://platform.mediastre.am/analytics/now')\n",
    "    token = r.cookies.get_dict()[\"jwt\"]\n",
    "    headers = {\"X-API-Token\": token}\n",
    "    endpoint = \"https://metrics.mdstrm.com/outbound/v1/metric/api\"\n",
    "\n",
    "    return headers, endpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_current_data():\n",
    "\n",
    "    f_inicio_consulta = (now_dt + timedelta(days= - dias_reemplazo)).date().strftime(fmt_d)\n",
    "\n",
    "    client = bigquery.Client.from_service_account_json(_google_key) \n",
    "\n",
    "    update_job_d = client.query(\n",
    "        \"\"\"\n",
    "        DELETE FROM `{0}`\n",
    "        WHERE fecha_termino >= '{1}'\n",
    "        \"\"\".format(bq_table, f_inicio_consulta))  \n",
    "    \n",
    "    print(f'Borrando periodo diario desde: ' + f_inicio_consulta)       \n",
    "    print(update_job_d.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2022-07-01 04:00:00', '2022-07-29 04:00:00'],\n",
       " ['2022-07-01 04:00:00', '2022-07-30 04:00:00'],\n",
       " ['2022-07-01 04:00:00', '2022-07-31 04:00:00'],\n",
       " ['2022-07-01 04:00:00', '2022-08-01 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-02 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-03 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-04 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-05 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-06 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-07 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-08 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-09 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-10 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-11 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-12 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-13 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-14 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-15 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-16 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-17 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-18 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-19 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-20 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-21 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-22 04:00:00'],\n",
       " ['2022-08-01 04:00:00', '2022-08-23 04:00:00']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_array_dias() -> list: \n",
    "\n",
    "    \"\"\"Generación de la lista de los rangos de días a descargar desde la API de Mediastream\n",
    "\n",
    "    Returns:\n",
    "        list: lista de rangos de días a consultar \n",
    "    \"\"\"\n",
    "\n",
    "     # Se determinan las fechas de inicio y término de la consulta\n",
    "    dt_termino = datetime.now(cl)\n",
    "    fe_inicio = (dt_termino + timedelta(days=-dias_reemplazo)).date()\n",
    "    dt_inicio = datetime.combine(fe_inicio, time.min).astimezone(cl)\n",
    "\n",
    "    # Se genera un rango de fechas entre ambas\n",
    "    rango_dias = list(pd.date_range(dt_inicio, dt_termino, freq=\"1D\"))\n",
    "\n",
    "    rangos = []\n",
    "\n",
    "    for dia in rango_dias:\n",
    "        if dia.day== 1:\n",
    "            f_inicio = (dia + timedelta(days=-1)).replace(day=1)\n",
    "            f_inicio = datetime.combine(f_inicio.date(), time.min).astimezone(utc).strftime(fmt)\n",
    "            f_fin = dia.astimezone(utc).strftime(fmt)\n",
    "        else:\n",
    "            f_inicio = dia.replace(day=1)\n",
    "            f_inicio = datetime.combine(f_inicio.date(), time.min).astimezone(utc).strftime(fmt)\n",
    "            f_fin = dia.astimezone(utc).strftime(fmt)\n",
    "\n",
    "        rangos.append([f_inicio, f_fin])\n",
    "\n",
    "    # Se devuelve el listado de rangos a consultar\n",
    "    return rangos\n",
    "\n",
    "gen_array_dias()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_req(fechas: list, soporte: str) -> dict:\n",
    "\n",
    "    req = {}\n",
    "    req[\"name\"] = \"full_by_time\"\n",
    "    req[\"dimension\"] = [\"content_live\"]\n",
    "\n",
    "    req[\"filter\"] = [\n",
    "        {\"name\": \"date\", \"op\": [\">=\", \"<=\"], \"value\":fechas},\n",
    "        {\"name\": \"group\", \"value\": [grupo[soporte]],\n",
    "            \"logic_op\": \"and\", \"order\": 1}\n",
    "    ]\n",
    "\n",
    "    req[\"filter\"].append(\n",
    "        {\"name\": \"content_id\", \"value\": [content_live[soporte]], \n",
    "        \"logic_op\": \"and\", \"order\": 2})\n",
    "   \n",
    "    req[\"filter\"].append(\n",
    "        {\"name\": \"group\", \"value\": [stream_vip[5]], \n",
    "        \"logic_op\": \"and\", \"order\": 3})\n",
    "        \n",
    "    req[\"calendar\"] = {\"type\": \"all\"}\n",
    "    req[\"time\"] = \"0\"\n",
    "    req[\"trunc\"] = [\"MONTH\"]\n",
    "\n",
    "    return req\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_to_dataframe(response, soporte, vip):\n",
    "\n",
    "    df = pd.DataFrame(response.json()[\"data\"])\n",
    "\n",
    "    if df.empty:\n",
    "        return df\n",
    "   \n",
    "    df[\"soporte\"] = soporte\n",
    "    df[\"vip\"] = \"v{0}\".format(vip)\n",
    "\n",
    "    live_filter = {\n",
    "        \"horizonte.cl\": \"Horizonte\",\n",
    "        \"oasisfm.cl\": \"Oasis FM\",\n",
    "        \"playfm.cl\": \"Play FM\",\n",
    "        \"sonarfm.cl\": \"Sonar FM\",\n",
    "        \"tele13radio.cl\": \"Tele 13 Radio\"\n",
    "    }\n",
    "\n",
    "    df_2 = df[df[\"content_type\"].isin([\"OnDemand\", \"OPE\"])].copy()\n",
    "    if soporte != \"emisorpodcasting.cl\":\n",
    "        df_2 = df[df[\"content_live\"].isin([None, live_filter[soporte]])].copy()\n",
    "\n",
    "    return df_2[[\"soporte\", \"content_type\", \"vip\",\n",
    "                \"stream\", \"device\"]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descargar_data(soporte, fechas):\n",
    "    headers, endpoint = sesion_platform()\n",
    "\n",
    "    consultas = content_types[soporte]\n",
    "    print(\"Descargando datos: \" + soporte)\n",
    "    df_soporte = pd.DataFrame(columns=[\"soporte\"])\n",
    "\n",
    "    for content_type, vip in list(itertools.product(consultas, stream_vip.keys())):\n",
    "        fechas_con = fechas.copy()\n",
    "\n",
    "        print(\"{0}, {1}, {2}, vip {3}\".format(\n",
    "            fechas_con, soporte, content_type, vip))\n",
    "\n",
    "        req = generar_req(fechas_con, soporte)\n",
    "        response = requests.post(endpoint, headers=headers, json=req)\n",
    "\n",
    "        df = response_to_dataframe(response, soporte, vip)\n",
    "\n",
    "        if df.empty:\n",
    "            return df\n",
    "\n",
    "        df[\"fecha_inicio\"]= pd.to_datetime(fechas[0]).tz_localize(utc).tz_convert(cl).date()\n",
    "        df[\"fecha_termino\"]= pd.to_datetime(fechas[1]).tz_localize(utc).tz_convert(cl).date()\n",
    "\n",
    "        df_soporte = pd.concat([df_soporte, df])\n",
    "\n",
    "    df_soporte.sort_values(\n",
    "        by=[\"soporte\", \"fecha_inicio\",\"fecha_termino\",\"content_type\"], inplace=True)\n",
    "    df_soporte=df_soporte[[\"soporte\", \"fecha_inicio\", \"fecha_termino\", \"content_type\", \"vip\", \"stream\", \"device\"]]\n",
    "    df_soporte.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_soporte\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_bq(df):\n",
    "\n",
    "    client = bigquery.Client.from_service_account_json(_google_key)\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        schema=[],\n",
    "        clustering_fields=[\"soporte\", \"content_type\", \"vip\"],\n",
    "        time_partitioning=bigquery.TimePartitioning(\n",
    "            type_=bigquery.TimePartitioningType.MONTH,\n",
    "            field=\"fecha_inicio\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    job = client.load_table_from_dataframe(df, bq_table, job_config=job_config)\n",
    "\n",
    "    print(job.result()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_horizonte():\n",
    "        \n",
    "    rango= gen_array_dias()\n",
    "    df_total= pd.DataFrame()\n",
    "    \n",
    "    for fecha in rango:\n",
    "        df=descargar_data(\"horizonte.cl\", fecha)\n",
    "        df_total= pd.concat([df_total, df])\n",
    "    upload_to_bq(df_total)\n",
    "\n",
    "def etl_oasis():\n",
    "        \n",
    "    rango= gen_array_dias()\n",
    "    df_total= pd.DataFrame()\n",
    "    \n",
    "    for fecha in rango:\n",
    "        df=descargar_data(\"oasisfm.cl\", fecha)\n",
    "        df_total= pd.concat([df_total, df])\n",
    "    upload_to_bq(df_total)\n",
    "\n",
    "def etl_play():\n",
    "        \n",
    "    rango= gen_array_dias()\n",
    "    df_total= pd.DataFrame()\n",
    "    \n",
    "    for fecha in rango:\n",
    "        df=descargar_data(\"playfm.cl\", fecha)\n",
    "        df_total= pd.concat([df_total, df])\n",
    "    upload_to_bq(df_total)\n",
    "\n",
    "def etl_sonar():\n",
    "        \n",
    "    rango= gen_array_dias()\n",
    "    df_total= pd.DataFrame()\n",
    "    \n",
    "    for fecha in rango:\n",
    "        df=descargar_data(\"sonarfm.cl\", fecha)\n",
    "        df_total= pd.concat([df_total, df])\n",
    "    upload_to_bq(df_total)\n",
    "\n",
    "def etl_tele13radio():\n",
    "        \n",
    "    rango= gen_array_dias()\n",
    "    df_total= pd.DataFrame()\n",
    "    \n",
    "    for fecha in rango:\n",
    "        df=descargar_data(\"tele13radio.cl\", fecha)\n",
    "        df_total= pd.concat([df_total, df])\n",
    "    upload_to_bq(df_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando datos: tele13radio.cl\n",
      "['2022-07-01 04:00:00', '2022-07-28 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-07-01 04:00:00', '2022-07-29 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-07-01 04:00:00', '2022-07-30 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-07-01 04:00:00', '2022-07-31 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-07-01 04:00:00', '2022-08-01 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-02 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-03 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-04 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-05 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-06 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-07 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-08 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-09 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-10 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-11 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-12 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-13 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-14 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-15 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-16 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-17 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-18 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-19 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-20 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-21 04:00:00'], tele13radio.cl, None, vip 5\n",
      "Descargando datos: tele13radio.cl\n",
      "['2022-08-01 04:00:00', '2022-08-22 04:00:00'], tele13radio.cl, None, vip 5\n",
      "LoadJob<project=conexion-datos-rdf, location=US, id=ff8a6c61-62c9-4684-bd9d-4e2ebe50fa58>\n"
     ]
    }
   ],
   "source": [
    "#del_current_data()\n",
    "#etl_horizonte()\n",
    "#etl_oasis()\n",
    "#etl_play()\n",
    "#etl_sonar()\n",
    "#etl_tele13radio()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c6fbda2488a67f21337359f03bca5305f1d74b510f165862164d92d24f216f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
